{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <2D1B8D5C-7891-3680-9CF9-F771AE880676> /Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <ADC0A61A-5B83-3A02-975F-EE5DFF441305> /Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset  \n",
       "0  vidir_modern  \n",
       "1  vidir_modern  \n",
       "2  vidir_modern  \n",
       "3  vidir_modern  \n",
       "4  vidir_modern  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(\"HAM10000_metadata\")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0025030.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0026769.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0025661.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_2\\ISIC_0031633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAM_0005132</td>\n",
       "      <td>ISIC_0025837</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0025837.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age     sex localization  \\\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0    male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0    male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0    male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0    male          ear   \n",
       "8  HAM_0005132  ISIC_0025837  bkl   histo  70.0  female         back   \n",
       "\n",
       "        dataset                                 img_path  \n",
       "1  vidir_modern  HAM10000_images_part_1\\ISIC_0025030.jpg  \n",
       "2  vidir_modern  HAM10000_images_part_1\\ISIC_0026769.jpg  \n",
       "3  vidir_modern  HAM10000_images_part_1\\ISIC_0025661.jpg  \n",
       "4  vidir_modern  HAM10000_images_part_2\\ISIC_0031633.jpg  \n",
       "8  vidir_modern  HAM10000_images_part_1\\ISIC_0025837.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img_path = {os.path.splitext(os.path.basename(x))[0]: x for x in glob((os.path.join('*', '*.jpg')))}\n",
    "\n",
    "df_data['img_path'] = df_data['image_id'].map(img_path.get)\n",
    "\n",
    "#drop rows with no image path\n",
    "df_data.dropna(inplace=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        return np.asarray(image.resize((32, 32)))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image '{image_path}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(img):\n",
    "    return np.transpose(img, (2, 0 ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
=======
   "execution_count": 5,
>>>>>>> main
=======
   "execution_count": 5,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>img_path</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0025030.jpg</td>\n",
       "      <td>[[[24, 56, 106, 143, 167, 173, 177, 178, 185, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0026769.jpg</td>\n",
       "      <td>[[[190, 199, 200, 205, 207, 207, 209, 201, 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0025661.jpg</td>\n",
       "      <td>[[[35, 83, 128, 161, 174, 180, 191, 192, 199, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_2\\ISIC_0031633.jpg</td>\n",
       "      <td>[[[155, 188, 210, 220, 228, 233, 235, 234, 238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAM_0005132</td>\n",
       "      <td>ISIC_0025837</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0025837.jpg</td>\n",
       "      <td>[[[122, 158, 179, 184, 191, 188, 194, 195, 199...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age     sex localization  \\\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0    male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0    male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0    male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0    male          ear   \n",
       "8  HAM_0005132  ISIC_0025837  bkl   histo  70.0  female         back   \n",
       "\n",
       "        dataset                                 img_path  \\\n",
       "1  vidir_modern  HAM10000_images_part_1\\ISIC_0025030.jpg   \n",
       "2  vidir_modern  HAM10000_images_part_1\\ISIC_0026769.jpg   \n",
       "3  vidir_modern  HAM10000_images_part_1\\ISIC_0025661.jpg   \n",
       "4  vidir_modern  HAM10000_images_part_2\\ISIC_0031633.jpg   \n",
       "8  vidir_modern  HAM10000_images_part_1\\ISIC_0025837.jpg   \n",
       "\n",
       "                                                 img  \n",
       "1  [[[24, 56, 106, 143, 167, 173, 177, 178, 185, ...  \n",
       "2  [[[190, 199, 200, 205, 207, 207, 209, 201, 199...  \n",
       "3  [[[35, 83, 128, 161, 174, 180, 191, 192, 199, ...  \n",
       "4  [[[155, 188, 210, 220, 228, 233, 235, 234, 238...  \n",
       "8  [[[122, 158, 179, 184, 191, 188, 194, 195, 199...  "
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 138,
=======
     "execution_count": 5,
>>>>>>> main
=======
     "execution_count": 5,
>>>>>>> main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['img'] = df_data['img_path'].map(load_image)\n",
    "df_data['img'] = df_data['img'].apply(transpose)\n",
    "df_data.dropna()\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 139,
=======
   "execution_count": 6,
>>>>>>> main
=======
   "execution_count": 6,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8039, 10)\n",
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(df_data.shape)\n",
    "print(df_data['img'].iloc[10].shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 140,
=======
   "execution_count": 7,
>>>>>>> main
=======
   "execution_count": 7,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 32, 32) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGreys_r\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mgca()\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    454\u001b[0m     warn_deprecated(\n\u001b[0;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\matplotlib\\pyplot.py:2650\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   2645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   2646\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2647\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2648\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[0;32m   2649\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2650\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[0;32m   2651\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm, aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[0;32m   2652\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation, alpha\u001b[38;5;241m=\u001b[39malpha, vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[0;32m   2653\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax, origin\u001b[38;5;241m=\u001b[39morigin, extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[0;32m   2654\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   2655\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm, filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   2656\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   2657\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2658\u001b[0m     sci(__ret)\n\u001b[0;32m   2659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    454\u001b[0m     warn_deprecated(\n\u001b[0;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\matplotlib\\__init__.py:1414\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1414\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1416\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1417\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1418\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5487\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m   5481\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap, norm, interpolation,\n\u001b[0;32m   5482\u001b[0m                       origin, extent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   5483\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   5484\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5485\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 5487\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5488\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5490\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\matplotlib\\image.py:715\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    714\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[1;32m--> 715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    716\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (3, 32, 32) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(df_data['img'].iloc[10], cmap = \"Greys_r\")\n",
    "plt.gca().axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 141,
=======
   "execution_count": 8,
>>>>>>> main
=======
   "execution_count": 8,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>HAM_0000827</td>\n",
       "      <td>[[[168, 176, 178, 179, 178, 185, 184, 184, 191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>HAM_0001389</td>\n",
       "      <td>[[[140, 148, 154, 163, 165, 171, 172, 172, 173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>HAM_0002885</td>\n",
       "      <td>[[[242, 234, 240, 244, 244, 245, 247, 246, 246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6162</th>\n",
       "      <td>HAM_0002309</td>\n",
       "      <td>[[[232, 233, 236, 236, 237, 237, 239, 239, 240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7735</th>\n",
       "      <td>HAM_0006567</td>\n",
       "      <td>[[[183, 182, 184, 185, 187, 190, 190, 191, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>HAM_0003747</td>\n",
       "      <td>[[[225, 225, 223, 222, 224, 228, 228, 229, 232...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6832</th>\n",
       "      <td>HAM_0000464</td>\n",
       "      <td>[[[160, 165, 169, 172, 172, 174, 177, 183, 185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>HAM_0003715</td>\n",
       "      <td>[[[215, 218, 220, 217, 214, 218, 219, 221, 222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9457</th>\n",
       "      <td>HAM_0000675</td>\n",
       "      <td>[[[164, 168, 172, 175, 175, 175, 177, 180, 182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9031</th>\n",
       "      <td>HAM_0002228</td>\n",
       "      <td>[[[145, 153, 154, 156, 160, 163, 166, 169, 174...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6431 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id                                                img\n",
       "1156  HAM_0000827  [[[168, 176, 178, 179, 178, 185, 184, 184, 191...\n",
       "373   HAM_0001389  [[[140, 148, 154, 163, 165, 171, 172, 172, 173...\n",
       "5382  HAM_0002885  [[[242, 234, 240, 244, 244, 245, 247, 246, 246...\n",
       "6162  HAM_0002309  [[[232, 233, 236, 236, 237, 237, 239, 239, 240...\n",
       "7735  HAM_0006567  [[[183, 182, 184, 185, 187, 190, 190, 191, 192...\n",
       "...           ...                                                ...\n",
       "6604  HAM_0003747  [[[225, 225, 223, 222, 224, 228, 228, 229, 232...\n",
       "6832  HAM_0000464  [[[160, 165, 169, 172, 172, 174, 177, 183, 185...\n",
       "1081  HAM_0003715  [[[215, 218, 220, 217, 214, 218, 219, 221, 222...\n",
       "9457  HAM_0000675  [[[164, 168, 172, 175, 175, 175, 177, 180, 182...\n",
       "9031  HAM_0002228  [[[145, 153, 154, 156, 160, 163, 166, 169, 174...\n",
       "\n",
       "[6431 rows x 2 columns]"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 141,
=======
     "execution_count": 8,
>>>>>>> main
=======
     "execution_count": 8,
>>>>>>> main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data[['lesion_id', 'img']], df_data['dx'], test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 142,
=======
   "execution_count": 38,
>>>>>>> main
=======
   "execution_count": 38,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "(6431, 3)\n",
      "(1608, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6431, 3072])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
=======
=======
>>>>>>> main
      "tensor([[168., 127., 129.,  ...,  49.,  25.,  31.],\n",
      "        [140., 117., 129.,  ..., 101.,  73.,  93.],\n",
      "        [242., 169., 181.,  ..., 220., 154., 145.],\n",
      "        ...,\n",
      "        [215., 147., 140.,  ..., 188., 115., 109.],\n",
      "        [164., 136., 147.,  ..., 156., 123., 137.],\n",
      "        [145., 119., 120.,  ..., 169., 150., 159.]])\n"
     ]
<<<<<<< HEAD
>>>>>>> main
=======
>>>>>>> main
    }
   ],
   "source": [
    "n, p = X_train.shape[0], X_train.shape[1] - 1\n",
    "\n",
    "img_tensors = [torch.Tensor(img) for img in X_train['img'].values]\n",
    "X_train['img_tensor'] = img_tensors\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "print(X_train.shape)\n",
    "\n",
    "img_tensors_tst = [torch.Tensor(img) for img in X_test['img'].values]\n",
    "X_test['img_tensor'] = img_tensors_tst\n",
    "print(X_test.shape)\n",
=======
    "#print(X_train.shape)\n",
    "#print(X_train[\"img\"][10])\n",
>>>>>>> main
=======
    "#print(X_train.shape)\n",
    "#print(X_train[\"img\"][10])\n",
>>>>>>> main
    "\n",
    "X_train_flat = torch.stack([img.flatten() for img in X_train['img_tensor']])\n",
    "#X_train_flat.shape\n",
    "print(X_train_flat)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 143,
=======
   "execution_count": 10,
>>>>>>> main
=======
   "execution_count": 10,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "f = LR.fit(X_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 144,
=======
   "execution_count": 11,
>>>>>>> main
=======
   "execution_count": 11,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[168., 176., 178.,  ...,  90.,  56.,  31.],\n",
       "        [140., 148., 154.,  ..., 124., 109.,  93.],\n",
       "        [242., 234., 240.,  ..., 151., 147., 145.],\n",
       "        ...,\n",
       "        [215., 218., 220.,  ..., 118., 116., 109.],\n",
       "        [164., 168., 172.,  ..., 153., 139., 137.],\n",
       "        [145., 153., 154.,  ..., 166., 166., 159.]])"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 144,
=======
     "execution_count": 11,
>>>>>>> main
=======
     "execution_count": 11,
>>>>>>> main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flat"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 145,
=======
   "execution_count": 12,
>>>>>>> main
=======
   "execution_count": 12,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017571139791634"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 145,
=======
     "execution_count": 12,
>>>>>>> main
=======
     "execution_count": 12,
>>>>>>> main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(X_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Net\n",
    "We already flattened the data, so that's pretty cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, MaxPool2d, Parameter\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "import torch.nn as nn\n",
    "from  torch.nn import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n",
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train['img'].iloc[0].shape)\n",
    "print(X_test['img'].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img = torch.stack([torch.from_numpy(img) for img in X_train['img'].tolist()])\n",
    "y_train = torch.Tensor(y_train.tolist())\n",
    "\n",
    "X_test_img = torch.stack([torch.from_numpy(img) for img in X_test['img'].tolist()])\n",
    "y_test = torch.Tensor(y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_train_img, y_train),\n",
    "    batch_size = 32,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_test_img, y_test),\n",
    "    batch_size = 32,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "X, y = next(iter(data_loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pipeline = torch.nn.Sequential(\n",
    "            nn.Conv2d(3, 100, 5),\n",
    "            ReLU(),\n",
    "            nn.Conv2d(100, 50, 3),\n",
    "            ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(50, 50, 3),\n",
    "            ReLU(),\n",
    "            nn.Conv2d(50, 50, 3),\n",
    "            ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(800, 512),\n",
    "            ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            ReLU(),\n",
    "            nn.Linear(128, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipeline(x)\n",
    "    \n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 100, 28, 28]           7,600\n",
      "              ReLU-2          [-1, 100, 28, 28]               0\n",
      "            Conv2d-3           [-1, 50, 26, 26]          45,050\n",
      "              ReLU-4           [-1, 50, 26, 26]               0\n",
      "         MaxPool2d-5           [-1, 50, 13, 13]               0\n",
      "            Conv2d-6           [-1, 50, 11, 11]          22,550\n",
      "              ReLU-7           [-1, 50, 11, 11]               0\n",
      "            Conv2d-8             [-1, 50, 9, 9]          22,550\n",
      "              ReLU-9             [-1, 50, 9, 9]               0\n",
      "        MaxPool2d-10             [-1, 50, 4, 4]               0\n",
      "          Flatten-11                  [-1, 800]               0\n",
      "           Linear-12                  [-1, 512]         410,112\n",
      "             ReLU-13                  [-1, 512]               0\n",
      "           Linear-14                  [-1, 128]          65,664\n",
      "             ReLU-15                  [-1, 128]               0\n",
      "           Linear-16                    [-1, 7]             903\n",
      "================================================================\n",
      "Total params: 574,429\n",
      "Trainable params: 574,429\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.95\n",
      "Params size (MB): 2.19\n",
      "Estimated Total Size (MB): 4.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, multichannel = False):\n",
    "\n",
    "    # count the number of total observations and correct predictions\n",
    "    total = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    # loop through the data loader\n",
    "    for X, y in data_loader_val:\n",
    "        X = X.float()\n",
    "        y = y.long()\n",
    "\n",
    "        # used for evaluating ImageNet later\n",
    "        if multichannel:\n",
    "            X = torch.tile(X, dims = (1, 3, 1, 1))\n",
    "\n",
    "        # move the data to the device (ideally, to gpu)\n",
    "\n",
    "        # compute the predictions\n",
    "        scores = model.forward(X)\n",
    "        y_pred =  torch.argmax(scores, dim = 1)\n",
    "\n",
    "        # update the total and the number of correct predictions\n",
    "        total += X.size(0)\n",
    "        total_correct += (y_pred == y).sum().item()\n",
    "\n",
    "    print(f\"validation accuracy = {total_correct / total:.3f}\")\n",
    "#--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def train(model, k_epochs = 1, print_every = 2000, evaluate_after_epoch = True, multichannel = False, **opt_kwargs):\n",
    "\n",
    "        # loss function is cross-entropy (multiclass logistic)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # optimizer is SGD with momentum\n",
    "    optimizer = optim.SGD(model.parameters(), **opt_kwargs)\n",
    "\n",
    "    for epoch in range(k_epochs):\n",
    "        for i, data in enumerate(data_loader_train):\n",
    "            X, y = data\n",
    "            X = X.float()\n",
    "            y = y.long()\n",
    "            \n",
    "            if multichannel:\n",
    "                X = torch.tile(X, dims = (1, 3, 1, 1))\n",
    "\n",
    "            # clear any accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute the loss\n",
    "            y_pred = model(X)\n",
    "            loss   = loss_fn(y_pred, y)\n",
    "\n",
    "            # compute gradients and carry out an optimization step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % print_every == 0:\n",
    "                print(f\"Epoch {epoch}, batch {i:>3}, loss on batch: {loss.item():.3f}\")\n",
    "\n",
    "        if evaluate_after_epoch:\n",
    "            print(f\"Epoch {epoch}: \", end = \"\")\n",
    "            evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: validation accuracy = 0.654\n",
      "Epoch 1: validation accuracy = 0.663\n",
      "Epoch 2: validation accuracy = 0.653\n",
      "Epoch 3: validation accuracy = 0.654\n",
      "Epoch 4: validation accuracy = 0.653\n"
     ]
    }
   ],
   "source": [
    "train(model, k_epochs = 5,  lr = 0.01, evaluate_after_epoch = True, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip and rotate an image to increase dataset size"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 123,
>>>>>>> main
=======
   "execution_count": 123,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed image\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "# define desired transforms\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomRotation(90),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    ])\n",
    "\n",
    "# prints image given ndarray representation\n",
    "def show_image(img_array):\n",
    "    plt.imshow(img_array, cmap = \"Greys_r\")\n",
    "    plt.gca().axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# define an image to transform (eventually -- loop through all images?)\n",
    "img = X_train['img'][22]\n",
    "\n",
    "### original image\n",
    "print(\"original image\")\n",
    "show_image(img)\n",
    "\n",
    "### transformed image\n",
    "print(\"transformed image\")\n",
    "# convert image to PIL (python imaging library). Transforms are finicky\n",
    "pil = Image.fromarray(img) \n",
    "# apply transforms\n",
    "img_transformed = transforms(pil)\n",
    "# convert back to numpy array (for eventually adding into df)\n",
    "img_np = np.array(img_transformed)\n",
    "show_image(img_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
