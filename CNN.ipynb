{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <2D1B8D5C-7891-3680-9CF9-F771AE880676> /Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <ADC0A61A-5B83-3A02-975F-EE5DFF441305> /Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset  \n",
       "0  vidir_modern  \n",
       "1  vidir_modern  \n",
       "2  vidir_modern  \n",
       "3  vidir_modern  \n",
       "4  vidir_modern  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(\"HAM10000_metadata\")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1/ISIC_0025030.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1/ISIC_0026769.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1/ISIC_0025661.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_2/ISIC_0031633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAM_0005132</td>\n",
       "      <td>ISIC_0025837</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1/ISIC_0025837.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age     sex localization  \\\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0    male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0    male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0    male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0    male          ear   \n",
       "8  HAM_0005132  ISIC_0025837  bkl   histo  70.0  female         back   \n",
       "\n",
       "        dataset                                 img_path  \n",
       "1  vidir_modern  HAM10000_images_part_1/ISIC_0025030.jpg  \n",
       "2  vidir_modern  HAM10000_images_part_1/ISIC_0026769.jpg  \n",
       "3  vidir_modern  HAM10000_images_part_1/ISIC_0025661.jpg  \n",
       "4  vidir_modern  HAM10000_images_part_2/ISIC_0031633.jpg  \n",
       "8  vidir_modern  HAM10000_images_part_1/ISIC_0025837.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img_path = {os.path.splitext(os.path.basename(x))[0]: x for x in glob((os.path.join('*', '*.jpg')))}\n",
    "\n",
    "df_data['img_path'] = df_data['image_id'].map(img_path.get)\n",
    "\n",
    "#drop rows with no image path\n",
    "df_data.dropna(inplace=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        return np.asarray(image.resize((32, 32)))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image '{image_path}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(img):\n",
    "    return np.transpose(img, (2, 0 ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>img_path</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1/ISIC_0025030.jpg</td>\n",
       "      <td>[[[24, 56, 106, 143, 167, 173, 177, 178, 185, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1/ISIC_0026769.jpg</td>\n",
       "      <td>[[[190, 199, 200, 205, 207, 207, 209, 201, 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1/ISIC_0025661.jpg</td>\n",
       "      <td>[[[35, 83, 128, 161, 174, 180, 191, 192, 199, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_2/ISIC_0031633.jpg</td>\n",
       "      <td>[[[155, 188, 210, 220, 228, 233, 235, 234, 238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAM_0005132</td>\n",
       "      <td>ISIC_0025837</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>HAM10000_images_part_1/ISIC_0025837.jpg</td>\n",
       "      <td>[[[122, 158, 179, 184, 191, 188, 194, 195, 199...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age     sex localization  \\\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0    male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0    male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0    male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0    male          ear   \n",
       "8  HAM_0005132  ISIC_0025837  bkl   histo  70.0  female         back   \n",
       "\n",
       "        dataset                                 img_path  \\\n",
       "1  vidir_modern  HAM10000_images_part_1/ISIC_0025030.jpg   \n",
       "2  vidir_modern  HAM10000_images_part_1/ISIC_0026769.jpg   \n",
       "3  vidir_modern  HAM10000_images_part_1/ISIC_0025661.jpg   \n",
       "4  vidir_modern  HAM10000_images_part_2/ISIC_0031633.jpg   \n",
       "8  vidir_modern  HAM10000_images_part_1/ISIC_0025837.jpg   \n",
       "\n",
       "                                                 img  \n",
       "1  [[[24, 56, 106, 143, 167, 173, 177, 178, 185, ...  \n",
       "2  [[[190, 199, 200, 205, 207, 207, 209, 201, 199...  \n",
       "3  [[[35, 83, 128, 161, 174, 180, 191, 192, 199, ...  \n",
       "4  [[[155, 188, 210, 220, 228, 233, 235, 234, 238...  \n",
       "8  [[[122, 158, 179, 184, 191, 188, 194, 195, 199...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['img'] = df_data['img_path'].map(load_image)\n",
    "df_data['img'] = df_data['img'].apply(transpose)\n",
    "df_data.dropna()\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8039, 10)\n",
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(df_data.shape)\n",
    "print(df_data['img'].iloc[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = df_data['img'].iloc[10]\n",
    "img = np.transpose(img, (1, 2, 0))\n",
    "plt.imshow(img, cmap = \"Greys_r\")\n",
    "plt.gca().axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>HAM_0000827</td>\n",
       "      <td>[[[168, 176, 178, 179, 178, 185, 184, 184, 191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>HAM_0001389</td>\n",
       "      <td>[[[140, 148, 154, 163, 165, 171, 172, 172, 173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>HAM_0002885</td>\n",
       "      <td>[[[242, 234, 240, 244, 244, 245, 247, 246, 246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6162</th>\n",
       "      <td>HAM_0002309</td>\n",
       "      <td>[[[232, 233, 236, 236, 237, 237, 239, 239, 240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7735</th>\n",
       "      <td>HAM_0006567</td>\n",
       "      <td>[[[183, 182, 184, 185, 187, 190, 190, 191, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>HAM_0003747</td>\n",
       "      <td>[[[225, 225, 223, 222, 224, 228, 228, 229, 232...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6832</th>\n",
       "      <td>HAM_0000464</td>\n",
       "      <td>[[[160, 165, 169, 172, 172, 174, 177, 183, 185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>HAM_0003715</td>\n",
       "      <td>[[[215, 218, 220, 217, 214, 218, 219, 221, 222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9457</th>\n",
       "      <td>HAM_0000675</td>\n",
       "      <td>[[[164, 168, 172, 175, 175, 175, 177, 180, 182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9031</th>\n",
       "      <td>HAM_0002228</td>\n",
       "      <td>[[[145, 153, 154, 156, 160, 163, 166, 169, 174...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6431 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id                                                img\n",
       "1156  HAM_0000827  [[[168, 176, 178, 179, 178, 185, 184, 184, 191...\n",
       "373   HAM_0001389  [[[140, 148, 154, 163, 165, 171, 172, 172, 173...\n",
       "5382  HAM_0002885  [[[242, 234, 240, 244, 244, 245, 247, 246, 246...\n",
       "6162  HAM_0002309  [[[232, 233, 236, 236, 237, 237, 239, 239, 240...\n",
       "7735  HAM_0006567  [[[183, 182, 184, 185, 187, 190, 190, 191, 192...\n",
       "...           ...                                                ...\n",
       "6604  HAM_0003747  [[[225, 225, 223, 222, 224, 228, 228, 229, 232...\n",
       "6832  HAM_0000464  [[[160, 165, 169, 172, 172, 174, 177, 183, 185...\n",
       "1081  HAM_0003715  [[[215, 218, 220, 217, 214, 218, 219, 221, 222...\n",
       "9457  HAM_0000675  [[[164, 168, 172, 175, 175, 175, 177, 180, 182...\n",
       "9031  HAM_0002228  [[[145, 153, 154, 156, 160, 163, 166, 169, 174...\n",
       "\n",
       "[6431 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data[['lesion_id', 'img']], df_data['dx'], test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/3yjvm85j3rq1vhh53yn6cy0r0000gn/T/ipykernel_70938/3824429122.py:3: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  img_tensors = [torch.Tensor(img) for img in X_train['img'].values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6431, 3)\n",
      "(1608, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6431, 3072])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, p = X_train.shape[0], X_train.shape[1] - 1\n",
    "\n",
    "img_tensors = [torch.Tensor(img) for img in X_train['img'].values]\n",
    "X_train['img_tensor'] = img_tensors\n",
    "print(X_train.shape)\n",
    "\n",
    "img_tensors_tst = [torch.Tensor(img) for img in X_test['img'].values]\n",
    "X_test['img_tensor'] = img_tensors_tst\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train_flat = torch.stack([img.flatten() for img in X_train['img_tensor']])\n",
    "X_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar plot: diagnosis\n",
    "y_train\n",
    "#y_train.plot(kind = 'bar')\n",
    "\n",
    "# Count the occurrences of each class in y_train\n",
    "counts = np.bincount(y_train)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(range(len(counts)), counts)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "f = LR.fit(X_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[168., 176., 178.,  ...,  90.,  56.,  31.],\n",
       "        [140., 148., 154.,  ..., 124., 109.,  93.],\n",
       "        [242., 234., 240.,  ..., 151., 147., 145.],\n",
       "        ...,\n",
       "        [215., 218., 220.,  ..., 118., 116., 109.],\n",
       "        [164., 168., 172.,  ..., 153., 139., 137.],\n",
       "        [145., 153., 154.,  ..., 166., 166., 159.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017571139791634"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(X_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Net\n",
    "We already flattened the data, so that's pretty cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, MaxPool2d, Parameter\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "import torch.nn as nn\n",
    "from  torch.nn import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n",
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train['img'].iloc[0].shape)\n",
    "print(X_test['img'].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img = torch.stack([torch.from_numpy(img) for img in X_train['img'].tolist()])\n",
    "y_train = torch.Tensor(y_train.tolist())\n",
    "\n",
    "X_test_img = torch.stack([torch.from_numpy(img) for img in X_test['img'].tolist()])\n",
    "y_test = torch.Tensor(y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_train_img, y_train),\n",
    "    batch_size = 100,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_test_img, y_test),\n",
    "    batch_size = 100,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "X, y = next(iter(data_loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, multichannel = False):\n",
    "\n",
    "    # count the number of total observations and correct predictions\n",
    "    total = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    # loop through the data loader\n",
    "    for X, y in data_loader_val:\n",
    "        X = X.float()\n",
    "        y = y.long()\n",
    "\n",
    "        # used for evaluating ImageNet later\n",
    "        if multichannel:\n",
    "            X = torch.tile(X, dims = (1, 3, 1, 1))\n",
    "\n",
    "        # move the data to the device (ideally, to gpu)\n",
    "\n",
    "        # compute the predictions\n",
    "        scores = model.forward(X)\n",
    "        y_pred =  torch.argmax(scores, dim = 1)\n",
    "\n",
    "        # update the total and the number of correct predictions\n",
    "        total += X.size(0)\n",
    "        total_correct += (y_pred == y).sum().item()\n",
    "\n",
    "    print(f\"validation accuracy = {total_correct / total:.3f}\")\n",
    "#--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def train(model, k_epochs = 1, print_every = 2000, evaluate_after_epoch = True, multichannel = False, **opt_kwargs):\n",
    "\n",
    "        # loss function is cross-entropy (multiclass logistic)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # optimizer is SGD with momentum\n",
    "    optimizer = optim.SGD(model.parameters(), **opt_kwargs)\n",
    "\n",
    "    for epoch in range(k_epochs):\n",
    "        for i, data in enumerate(data_loader_train):\n",
    "            X, y = data\n",
    "            X = X.float()\n",
    "            y = y.long()\n",
    "            \n",
    "            if multichannel:\n",
    "                X = torch.tile(X, dims = (1, 3, 1, 1))\n",
    "\n",
    "            # clear any accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute the loss\n",
    "            y_pred = model(X)\n",
    "            loss   = loss_fn(y_pred, y)\n",
    "\n",
    "            # compute gradients and carry out an optimization step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % print_every == 0:\n",
    "                print(f\"Epoch {epoch}, batch {i:>3}, loss on batch: {loss.item():.3f}\")\n",
    "\n",
    "        if evaluate_after_epoch:\n",
    "            print(f\"Epoch {epoch}: \", end = \"\")\n",
    "            evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet_Simplest(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pipeline = torch.nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3072, 32)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipeline(x)\n",
    "    \n",
    "class ConvNet_class(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pipeline = torch.nn.Sequential(\n",
    "            nn.Conv2d(3, 100, 5),\n",
    "            ReLU(),\n",
    "            nn.Conv2d(100, 50, 3),\n",
    "            ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(50, 50, 3),\n",
    "            ReLU(),\n",
    "            nn.Conv2d(50, 50, 3),\n",
    "            ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(800, 512),\n",
    "            ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            ReLU(),\n",
    "            nn.Linear(128, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipeline(x)\n",
    "\n",
    "class ConvNet_Dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pipeline = torch.nn.Sequential(\n",
    "            nn.Conv2d(3, 100, 5),\n",
    "            ReLU(),\n",
    "            nn.Conv2d(100, 50, 3),\n",
    "            ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #nn.Dropout(0.25),\n",
    "            nn.Conv2d(50, 50, 3),\n",
    "            ReLU(),\n",
    "            nn.Conv2d(50, 50, 3),\n",
    "            ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #nn.Dropout(0.05),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(800, 512),\n",
    "            ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            ReLU(),\n",
    "            nn.Linear(128, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipeline(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a very simple neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                 [-1, 3072]               0\n",
      "            Linear-2                   [-1, 32]          98,336\n",
      "================================================================\n",
      "Total params: 98,336\n",
      "Trainable params: 98,336\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.38\n",
      "Estimated Total Size (MB): 0.41\n",
      "----------------------------------------------------------------\n",
      "Epoch 0: validation accuracy = 0.502\n",
      "Epoch 1: validation accuracy = 0.582\n",
      "Epoch 2: validation accuracy = 0.560\n",
      "Epoch 3: validation accuracy = 0.657\n",
      "Epoch 4: validation accuracy = 0.450\n",
      "Epoch 5: validation accuracy = 0.335\n",
      "Epoch 6: validation accuracy = 0.664\n",
      "Epoch 7: validation accuracy = 0.657\n",
      "Epoch 8: validation accuracy = 0.476\n",
      "Epoch 9: validation accuracy = 0.572\n",
      "Epoch 10: validation accuracy = 0.628\n",
      "Epoch 11: validation accuracy = 0.659\n",
      "Epoch 12: validation accuracy = 0.664\n",
      "Epoch 13: validation accuracy = 0.424\n",
      "Epoch 14: validation accuracy = 0.601\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet_Simplest()\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 32, 32))\n",
    "train(model, k_epochs = 15, lr = 0.1, evaluate_after_epoch = True, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the model we used in class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: validation accuracy = 0.654\n",
      "Epoch 1: validation accuracy = 0.653\n",
      "Epoch 2: validation accuracy = 0.654\n",
      "Epoch 3: validation accuracy = 0.669\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m ConvNet_class()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_after_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[90], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, k_epochs, print_every, evaluate_after_epoch, multichannel, **opt_kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# compute the loss\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m loss   \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# compute gradients and carry out an optimization step\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[91], line 37\u001b[0m, in \u001b[0;36mConvNet_class.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ConvNet_class()\n",
    "train(model, k_epochs = 5, lr = 0.01, evaluate_after_epoch = True, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oof. That's not good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we try including dropout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: validation accuracy = 0.037\n",
      "Epoch 1: validation accuracy = 0.037\n",
      "Epoch 2: validation accuracy = 0.037\n",
      "Epoch 3: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m ConvNet_Dropout()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_after_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 35\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, k_epochs, print_every, evaluate_after_epoch, multichannel, **opt_kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_after_epoch:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 19\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, multichannel)\u001b[0m\n\u001b[1;32m     14\u001b[0m     X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtile(X, dims \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# move the data to the device (ideally, to gpu)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# compute the predictions\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39margmax(scores, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# update the total and the number of correct predictions\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[81], line 65\u001b[0m, in \u001b[0;36mConvNet_Dropout.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-0451/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ConvNet_Dropout()\n",
    "train(model, k_epochs = 5, lr = 0.1, evaluate_after_epoch = True, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a model as recommended by a scientific paper on this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet_Expert(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pipeline = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=3),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(1024, 7),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipeline(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: validation accuracy = 0.654\n",
      "Epoch 1: validation accuracy = 0.654\n",
      "Epoch 2: validation accuracy = 0.654\n",
      "Epoch 3: validation accuracy = 0.654\n",
      "Epoch 4: validation accuracy = 0.654\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet_Expert()\n",
    "train(model, k_epochs = 5, lr = 0.1, evaluate_after_epoch = True, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not much better than the simplest neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of random crop and flip on an example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x283742520>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Experiment with a sample of the data\n",
    "X_train_flat = X_train_flat[1:10]\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(20, 20), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=1)\n",
    "    ])\n",
    "\n",
    "# original image\n",
    "print(\"original image\")\n",
    "plt.imshow(df_data['img'].iloc[10], cmap = \"Greys_r\")\n",
    "plt.gca().axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# transformed image\n",
    "print(\"transformed image\")\n",
    "img = Image.fromarray(df_data[\"img\"].iloc[10])\n",
    "img = transforms(img)\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
